{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this part of the exercise we will be experimenting with modifying audio in various ways to stretch / shrink it through time and to modify it's pitch.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part A: Interpolating over time.\n",
    "\n",
    "1. load 'audio_16k/Basta_16k.wav' audio file (note that it is on stereo)\n",
    "2. use `torch.nn.functional.interpolate` with `mode='bilinear` to stretch / compress the signal with 1.2, 0.8 factor respectfully.\n",
    "3. save these samples to outputs directory as 'interpolation_0_8.wav', 'interpolation_1_2.wav' and listen to them, do you notice something odd? why do you think this happens? - answear in a markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "audio, sample_rate = torchaudio.load('audio_16k/Basta_16k.wav')\n",
    "audio = audio.unsqueeze(0)\n",
    "audio = audio.unsqueeze(0)\n",
    "audio_08 = torch.nn.functional.interpolate(audio, scale_factor=0.8, mode='bilinear')\n",
    "audio_12 = torch.nn.functional.interpolate(audio, scale_factor=1.2, mode='bilinear')\n",
    "torchaudio.save('outputs/interpolation_0_8.wav', audio_08.squeeze(0).squeeze(0), sample_rate)\n",
    "torchaudio.save('outputs/interpolation_1_2.wav', audio_12.squeeze(0).squeeze(0), sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T14:01:43.364217Z",
     "end_time": "2023-04-30T14:02:59.722440Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part B: Naive time stretch (tempo shift).\n",
    "\n",
    "In this part you would be required to write a function that perform a SIMPLE augmentation over the audio:\n",
    "1. `naive_tempo_shift(wav, factor)` = stretch an audiofile by a given factor, e.g 0.8 factor should result a slowdown to 0.8x the original audio (output a LONGER wav). \n",
    "2. load 'audio_16k/Basta_16k.wav' and generate a tempo shift of x{0.8, 1.2} and save these generated audio files to outputs/naive_pitch_shift_{factor using _ instead if .}.wav\n",
    "\n",
    "Note: This should be a Naive implementation, achieveable using torch.stft, torch.istft, torch.fft.fft, torch.fft.ifft alone and programable in a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T13:19:30.751938Z",
     "end_time": "2023-04-30T14:03:08.005296Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 19\u001B[0m\n\u001B[0;32m     14\u001B[0m     stretched_wav \u001B[38;5;241m=\u001B[39m stretched_wav\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stretched_wav\n\u001B[1;32m---> 19\u001B[0m wav, sr \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maudio_16k/Basta_16k.wav\u001B[39m\u001B[38;5;124m'\u001B[39m, sr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16000\u001B[39m)\n\u001B[0;32m     20\u001B[0m wav_08 \u001B[38;5;241m=\u001B[39m naive_tempo_shift(wav, \u001B[38;5;241m0.8\u001B[39m)\n\u001B[0;32m     21\u001B[0m wav_12 \u001B[38;5;241m=\u001B[39m naive_tempo_shift(wav, \u001B[38;5;241m1.2\u001B[39m)\n",
      "Cell \u001B[1;32mIn[4], line 19\u001B[0m\n\u001B[0;32m     14\u001B[0m     stretched_wav \u001B[38;5;241m=\u001B[39m stretched_wav\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stretched_wav\n\u001B[1;32m---> 19\u001B[0m wav, sr \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maudio_16k/Basta_16k.wav\u001B[39m\u001B[38;5;124m'\u001B[39m, sr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16000\u001B[39m)\n\u001B[0;32m     20\u001B[0m wav_08 \u001B[38;5;241m=\u001B[39m naive_tempo_shift(wav, \u001B[38;5;241m0.8\u001B[39m)\n\u001B[0;32m     21\u001B[0m wav_12 \u001B[38;5;241m=\u001B[39m naive_tempo_shift(wav, \u001B[38;5;241m1.2\u001B[39m)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2023.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2023.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def naive_tempo_shift(wav, factor):\n",
    "    # Convert the waveform to a PyTorch tensor\n",
    "    wav_tensor = torch.from_numpy(wav)\n",
    "\n",
    "    # output_length = int(len(wav_tensor[0]) * factor)\n",
    "    # Compute the magnitude spectrogram of the audio\n",
    "    spec = torch.stft(wav_tensor, n_fft=2048, hop_length=512, return_complex=True)\n",
    "    # Compute the stretched waveform by inverting the spectrogram\n",
    "    stretched_wav = torch.istft(spec, n_fft=2048, hop_length=int(512 / factor))\n",
    "\n",
    "    return stretched_wav\n",
    "\n",
    "\n",
    "wav, sr = librosa.load('audio_16k/Basta_16k.wav', sr=16000, mono=False)\n",
    "wav_08 = naive_tempo_shift(wav, 0.8)\n",
    "wav_12 = naive_tempo_shift(wav, 1.2)\n",
    "torchaudio.save('outputs/naive_pitch_shift_0_8.wav', wav_08, sr)\n",
    "torchaudio.save('outputs/naive_pitch_shift_1_2.wav', wav_12, sr)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part C: Phase vocoder\n",
    "In this subsection you will implement version of a slightly better algorithm to perform time_stretch called Phase vocoder.\n",
    "We do not aim to get into depth of this algorithm design, yet we think that this algorithm is cool to know so in this part you will implement it from a given pseudo code.\n",
    "\n",
    "1. Implement the algorithm following the pseudo code below for the function time_stretch.\n",
    "2. Load 'audio_16k/Basta_16k.wav' and use time_stretch with factors x0.8, 1.2, save these generations to `outputs/phase_vocoder_{factor, replace '.' with '_'}.wav`\n",
    "3. Do you notice anything different from the previous naive time stretch (besides magnitude differences)? why do you think it is different?\n",
    "\n",
    "Guidance: use torch, torchaudio functions in this section. \n",
    "\n",
    "-\n",
    "Pseudo code:\n",
    "-\n",
    "\n",
    "time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "    complex_new_stft = view_as_complex(stack([re, im], dim=-1)) * abs(stft_right))\n",
    "    output = istft(complex_new_stft, win_length=win_size, hop_length=hop, window=hann_window)\n",
    "\n",
    "    return output\n",
    "\n",
    "-\n",
    "Pseudo functions:\n",
    "-\n",
    "\n",
    "construct_hann_window(win_size):\n",
    "    return a vector representing a hanning window, hint: see torch.hann_window\n",
    "\n",
    "get_complex_stft(signal, win_size, hop, window):\n",
    "    return a complex representation of the stft (x + jy form)\n",
    "\n",
    "get_acc_phase_delta(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "    phase_delta = angle(stft_right) - angle(stft_left)\n",
    "\n",
    "    # accumulate phase, follow this recursive formula\n",
    "    for i in {1...length(phase_delta)}: phase[i] := phase_delta[i] + phase[i-1]; phase[0] = phase_delta[0]\n",
    "    \n",
    "    # round phase back to [-2 * pi, 2 * pi] range\n",
    "    phase = phase  - (2 * pi * round(phase_delta / (2 * pi)))  \n",
    "\n",
    "    return phase\n",
    "\n",
    "get_re_im_from_phase(phase):\n",
    "    retrieves the real and imaginary components from a complex phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "    complex_new_stft = view_as_complex(stack([re, im], dim=-1)) * abs(stft_right))\n",
    "    output = istft(complex_new_stft, win_length=win_size, hop_length=hop, window=hann_window)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
