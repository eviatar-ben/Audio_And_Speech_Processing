{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this part of the exercise we will be experimenting with modifying audio in various ways to stretch / shrink it through time and to modify it's pitch.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part A: Interpolating over time.\n",
    "\n",
    "1. load 'audio_16k/Basta_16k.wav' audio file (note that it is on stereo)\n",
    "2. use `torch.nn.functional.interpolate` with `mode='bilinear` to stretch / compress the signal with 1.2, 0.8 factor respectfully.\n",
    "3. save these samples to outputs directory as 'interpolation_0_8.wav', 'interpolation_1_2.wav' and listen to them, do you notice something odd? why do you think this happens? - answear in a markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "audio, sample_rate = torchaudio.load('audio_16k/Basta_16k.wav')\n",
    "audio = audio.unsqueeze(0)\n",
    "audio = audio.unsqueeze(0)\n",
    "audio_08 = torch.nn.functional.interpolate(audio, scale_factor=0.8, mode='bilinear')\n",
    "audio_12 = torch.nn.functional.interpolate(audio, scale_factor=1.2, mode='bilinear')\n",
    "torchaudio.save('outputs/interpolation_0_8.wav', audio_08.squeeze(0).squeeze(0), sample_rate)\n",
    "torchaudio.save('outputs/interpolation_1_2.wav', audio_12.squeeze(0).squeeze(0), sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T00:31:57.242988Z",
     "end_time": "2023-04-30T00:31:57.293807Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part B: Naive time stretch (tempo shift).\n",
    "\n",
    "In this part you would be required to write a function that perform a SIMPLE augmentation over the audio:\n",
    "1. `naive_tempo_shift(wav, factor)` = stretch an audiofile by a given factor, e.g 0.8 factor should result a slowdown to 0.8x the original audio (output a LONGER wav). \n",
    "2. load 'audio_16k/Basta_16k.wav' and generate a tempo shift of x{0.8, 1.2} and save these generated audio files to outputs/naive_pitch_shift_{factor using _ instead if .}.wav\n",
    "\n",
    "Note: This should be a Naive implementation, achieveable using torch.stft, torch.istft, torch.fft.fft, torch.fft.ifft alone and programable in a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T02:05:22.948150Z",
     "end_time": "2023-04-30T02:07:22.281735Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "istft requires a complex-valued input tensor matching the output from stft with return_complex=True.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 20\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stretched_wav\n\u001B[0;32m     19\u001B[0m wav, sr \u001B[38;5;241m=\u001B[39m librosa\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maudio_16k/Basta_16k.wav\u001B[39m\u001B[38;5;124m'\u001B[39m, sr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16000\u001B[39m)\n\u001B[1;32m---> 20\u001B[0m wav_08 \u001B[38;5;241m=\u001B[39m \u001B[43mnaive_tempo_shift\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m wav_12 \u001B[38;5;241m=\u001B[39m naive_tempo_shift(wav, \u001B[38;5;241m1.2\u001B[39m)\n\u001B[0;32m     22\u001B[0m librosa\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39mwrite_wav(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputs/naive_pitch_shift_0_8.wav\u001B[39m\u001B[38;5;124m'\u001B[39m, wav_08, sr)\n",
      "Cell \u001B[1;32mIn[54], line 11\u001B[0m, in \u001B[0;36mnaive_tempo_shift\u001B[1;34m(wav, factor)\u001B[0m\n\u001B[0;32m      9\u001B[0m spec \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstft(wav_tensor, n_fft\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2048\u001B[39m, hop_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, return_complex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Compute the stretched waveform by inverting the spectrogram\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m stretched_wav \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mistft\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_fft\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhop_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Convert the stretched waveform back to a NumPy array\u001B[39;00m\n\u001B[0;32m     14\u001B[0m stretched_wav \u001B[38;5;241m=\u001B[39m stretched_wav\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[1;31mRuntimeError\u001B[0m: istft requires a complex-valued input tensor matching the output from stft with return_complex=True."
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "\n",
    "def naive_tempo_shift(wav, factor):\n",
    "    # Convert the waveform to a PyTorch tensor\n",
    "    wav_tensor = torch.from_numpy(wav)\n",
    "    output_length = int(len(wav_tensor)*factor)\n",
    "    # Compute the magnitude spectrogram of the audio\n",
    "    spec = torch.stft(wav_tensor, n_fft=2048, hop_length=512, return_complex=False)\n",
    "    # Compute the stretched waveform by inverting the spectrogram\n",
    "    stretched_wav = torch.istft(spec, n_fft=2048, hop_length=512, length=output_length, return_complex=False)\n",
    "\n",
    "    # Convert the stretched waveform back to a NumPy array\n",
    "    stretched_wav = stretched_wav.numpy()\n",
    "\n",
    "    return stretched_wav\n",
    "\n",
    "\n",
    "wav, sr = librosa.load('audio_16k/Basta_16k.wav', sr=16000)\n",
    "wav_08 = naive_tempo_shift(wav, 0.8)\n",
    "wav_12 = naive_tempo_shift(wav, 1.2)\n",
    "librosa.output.write_wav('outputs/naive_pitch_shift_0_8.wav', wav_08, sr)\n",
    "librosa.output.write_wav('outputs/naive_pitch_shift_1_2.wav', wav_12, sr)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part C: Phase vocoder\n",
    "In this subsection you will implement version of a slightly better algorithm to perform time_stretch called Phase vocoder.\n",
    "We do not aim to get into depth of this algorithm design, yet we think that this algorithm is cool to know so in this part you will implement it from a given pseudo code.\n",
    "\n",
    "1. Implement the algorithm following the pseudo code below for the function time_stretch.\n",
    "2. Load 'audio_16k/Basta_16k.wav' and use time_stretch with factors x0.8, 1.2, save these generations to `outputs/phase_vocoder_{factor, replace '.' with '_'}.wav`\n",
    "3. Do you notice anything different from the previous naive time stretch (besides magnitude differences)? why do you think it is different?\n",
    "\n",
    "Guidance: use torch, torchaudio functions in this section. \n",
    "\n",
    "-\n",
    "Pseudo code:\n",
    "-\n",
    "\n",
    "time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "    complex_new_stft = view_as_complex(stack([re, im], dim=-1)) * abs(stft_right))\n",
    "    output = istft(complex_new_stft, win_length=win_size, hop_length=hop, window=hann_window)\n",
    "\n",
    "    return output\n",
    "\n",
    "-\n",
    "Pseudo functions:\n",
    "-\n",
    "\n",
    "construct_hann_window(win_size):\n",
    "    return a vector representing a hanning window, hint: see torch.hann_window\n",
    "\n",
    "get_complex_stft(signal, win_size, hop, window):\n",
    "    return a complex representation of the stft (x + jy form)\n",
    "\n",
    "get_acc_phase_delta(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "    phase_delta = angle(stft_right) - angle(stft_left)\n",
    "\n",
    "    # accumulate phase, follow this recursive formula\n",
    "    for i in {1...length(phase_delta)}: phase[i] := phase_delta[i] + phase[i-1]; phase[0] = phase_delta[0]\n",
    "    \n",
    "    # round phase back to [-2 * pi, 2 * pi] range\n",
    "    phase = phase  - (2 * pi * round(phase_delta / (2 * pi)))  \n",
    "\n",
    "    return phase\n",
    "\n",
    "get_re_im_from_phase(phase):\n",
    "    retrieves the real and imaginary components from a complex phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code for this part here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
