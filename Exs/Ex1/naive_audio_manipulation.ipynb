{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this part of the exercise we will be experimenting with modifying audio in various ways to stretch / shrink it through time and to modify it's pitch.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part A: Interpolating over time.\n",
    "\n",
    "1. load 'audio_16k/Basta_16k.wav' audio file (note that it is on stereo)\n",
    "2. use `torch.nn.functional.interpolate` with `mode='bilinear` to stretch / compress the signal with 1.2, 0.8 factor respectfully.\n",
    "3. save these samples to outputs directory as 'interpolation_0_8.wav', 'interpolation_1_2.wav' and listen to them, do you notice something odd? why do you think this happens? - answear in a markdown cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "audio, sample_rate = torchaudio.load('audio_16k/Basta_16k.wav')\n",
    "audio = audio.unsqueeze(0)\n",
    "audio = audio.unsqueeze(0)\n",
    "audio_08 = torch.nn.functional.interpolate(audio, scale_factor=0.8, mode='bilinear')\n",
    "audio_12 = torch.nn.functional.interpolate(audio, scale_factor=1.2, mode='bilinear')\n",
    "torchaudio.save('outputs/interpolation_0_8.wav', audio_08.squeeze(0).squeeze(0), sample_rate)\n",
    "torchaudio.save('outputs/interpolation_1_2.wav', audio_12.squeeze(0).squeeze(0), sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T14:01:43.364217Z",
     "end_time": "2023-04-30T14:02:59.722440Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The interpoolation result in a different sized vector but the samplimg rate is not changed.\n",
    "listening to the files, we obsereved that the interpoolation with a factor of 0.8 resulted in a faster audio, and the interpoolation with a factor of 1.2 resulted in a slower audio. In addition, the pitch of the audio was changed - the audio with a factor of 0.8 had a higher pitch, and the audio with a factor of 1.2 had a lower pitch. We understand this phenomenon as a result of the interpoolation process, which stretches the audio wave in time, effectively increasing the distance between the signal's peaks, which decreases its frequency (resulting in a lower pitch). The opposite is true for the interpoolation with a factor of 0.8."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer non-code questions here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part B: Naive time stretch (tempo shift).\n",
    "\n",
    "In this part you would be required to write a function that perform a SIMPLE augmentation over the audio:\n",
    "1. `naive_tempo_shift(wav, factor)` = stretch an audiofile by a given factor, e.g 0.8 factor should result a slowdown to 0.8x the original audio (output a LONGER wav). \n",
    "2. load 'audio_16k/Basta_16k.wav' and generate a tempo shift of x{0.8, 1.2} and save these generated audio files to outputs/naive_pitch_shift_{factor using _ instead if .}.wav\n",
    "\n",
    "Note: This should be a Naive implementation, achieveable using torch.stft, torch.istft, torch.fft.fft, torch.fft.ifft alone and programable in a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T17:14:00.033711Z",
     "end_time": "2023-04-30T17:14:00.112221Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def naive_tempo_shift(wav, factor):\n",
    "    # Convert the waveform to a PyTorch tensor\n",
    "    wav_tensor = torch.from_numpy(wav)\n",
    "\n",
    "    # output_length = int(len(wav_tensor[0]) * factor)\n",
    "    # Compute the magnitude spectrogram of the audio\n",
    "    spec = torch.stft(wav_tensor, n_fft=2048, hop_length=512, return_complex=True)\n",
    "    # Compute the stretched waveform by inverting the spectrogram\n",
    "    stretched_wav = torch.istft(spec, n_fft=2048, hop_length=int(512 / factor))\n",
    "\n",
    "    return stretched_wav\n",
    "\n",
    "\n",
    "wav, sr = librosa.load('audio_16k/Basta_16k.wav', sr=16000, mono=False)\n",
    "wav_08 = naive_tempo_shift(wav, 0.8)\n",
    "wav_12 = naive_tempo_shift(wav, 1.2)\n",
    "torchaudio.save('outputs/naive_pitch_shift_0_8.wav', wav_08, sr)\n",
    "torchaudio.save('outputs/naive_pitch_shift_1_2.wav', wav_12, sr)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part C: Phase vocoder\n",
    "In this subsection you will implement version of a slightly better algorithm to perform time_stretch called Phase vocoder.\n",
    "We do not aim to get into depth of this algorithm design, yet we think that this algorithm is cool to know so in this part you will implement it from a given pseudo code.\n",
    "\n",
    "1. Implement the algorithm following the pseudo code below for the function time_stretch.\n",
    "2. Load 'audio_16k/Basta_16k.wav' and use time_stretch with factors x0.8, 1.2, save these generations to `outputs/phase_vocoder_{factor, replace '.' with '_'}.wav`\n",
    "3. Do you notice anything different from the previous naive time stretch (besides magnitude differences)? why do you think it is different?\n",
    "\n",
    "Guidance: use torch, torchaudio functions in this section. \n",
    "\n",
    "-\n",
    "Pseudo code:\n",
    "-\n",
    "\n",
    "time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "    complex_new_stft = view_as_complex(stack([re, im], dim=-1)) * abs(stft_right))\n",
    "    output = istft(complex_new_stft, win_length=win_size, hop_length=hop, window=hann_window)\n",
    "\n",
    "    return output\n",
    "\n",
    "-\n",
    "Pseudo functions:\n",
    "-\n",
    "\n",
    "construct_hann_window(win_size):\n",
    "    return a vector representing a hanning window, hint: see torch.hann_window\n",
    "\n",
    "get_complex_stft(signal, win_size, hop, window):\n",
    "    return a complex representation of the stft (x + jy form)\n",
    "\n",
    "get_acc_phase_delta(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "    phase_delta = angle(stft_right) - angle(stft_left)\n",
    "\n",
    "    # accumulate phase, follow this recursive formula\n",
    "    for i in {1...length(phase_delta)}: phase[i] := phase_delta[i] + phase[i-1]; phase[0] = phase_delta[0]\n",
    "    \n",
    "    # round phase back to [-2 * pi, 2 * pi] range\n",
    "    phase = phase  - (2 * pi * round(phase_delta / (2 * pi)))  \n",
    "\n",
    "    return phase\n",
    "\n",
    "get_re_im_from_phase(phase):\n",
    "    retrieves the real and imaginary components from a complex phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T17:14:17.270143Z",
     "end_time": "2023-04-30T17:14:17.458546Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "\n",
    "def construct_hann_window(win_size):\n",
    "    # return a vector representing a hanning window, hint: see torch.hann_window\n",
    "    hann_window = torch.hann_window(window_length=win_size)\n",
    "    return hann_window\n",
    "\n",
    "\n",
    "def get_complex_stft(signal, win_size, hop, window):\n",
    "    # Convert the waveform to a PyTorch tensor\n",
    "    # signal = torch.from_numpy(signal)\n",
    "    # return a complex representation of the stft (x + jy form)\n",
    "    stft = torch.stft(signal, n_fft=win_size, win_length=win_size, hop_length=hop, window=window, return_complex=True)\n",
    "    return stft\n",
    "\n",
    "\n",
    "def get_acc_phase_delta_1(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "    phase_delta = torch.angle(stft_right) - torch.angle(stft_left)\n",
    "\n",
    "    # accumulate phase, follow the recursive formula\n",
    "    phase = torch.zeros_like(phase_delta)\n",
    "    # phase = torch.zeros([2, 513, 1188])\n",
    "\n",
    "    phase[:, :, 0] = phase_delta[:, :, 0]\n",
    "    phase = torch.cumsum(phase_delta, axis=-1)\n",
    "\n",
    "    # round phase back to 0 - 2 * pi range\n",
    "    phase = phase - 2 * np.pi * torch.round(phase / (2 * np.pi))\n",
    "\n",
    "    return phase\n",
    "\n",
    "\n",
    "def get_acc_phase_delta(stft_left, stft_right):\n",
    "    # calculate angular distance between two complex STFTs\n",
    "\n",
    "    # phase_delta = angle(stft_right) - angle(stft_left)\n",
    "    phase_delta = torch.angle(stft_right) - torch.angle(stft_left)\n",
    "\n",
    "    # accumulate phase, follow this recursive formula\n",
    "    # for i in {1...length(phase_delta)}: phase[i] := phase_delta[i] + phase[i - 1];\n",
    "    # phase[0] = phase_delta[0]\n",
    "\n",
    "    phase = torch.zeros_like(phase_delta)\n",
    "    # phase = torch.zeros([2, 513, 1188])\n",
    "\n",
    "    phase[:, :, 0] = phase_delta[:, :, 0]\n",
    "    phase = torch.cumsum(phase_delta, axis=-1)\n",
    "\n",
    "    # round phase back to [-2 * pi, 2 * pi] range\n",
    "    # phase = phase - (2 * pi * round(phase_delta / (2 * pi)))\n",
    "\n",
    "    phase = phase - (2 * math.pi * torch.round(phase_delta / (2 * math.pi)))\n",
    "\n",
    "    return phase\n",
    "\n",
    "\n",
    "def get_re_im_from_phase(phase):\n",
    "    real = torch.cos(phase)\n",
    "    imag = torch.sin(phase)\n",
    "    return real, imag\n",
    "\n",
    "\n",
    "def time_stretch(signal, factor, win_size=1024, hop=1024 // 4):\n",
    "    # create window\n",
    "    hann_window = construct_hann_window(win_size)\n",
    "\n",
    "    # draw two complex STFTs\n",
    "    new_hop = int(hop * factor)\n",
    "    stft_left = get_complex_stft(signal[:, :-hop], win_size, new_hop, hann_window)\n",
    "    stft_right = get_complex_stft(signal[:, hop:], win_size, new_hop, hann_window)\n",
    "\n",
    "    # calculate accumulated phase delta and reconstruct phase from it\n",
    "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
    "\n",
    "    # reconstruct component from phase\n",
    "    re, im = get_re_im_from_phase(phase)\n",
    "\n",
    "    # perform stft  per channel\n",
    "    first_channel_complex_new_stft = torch.view_as_complex(\n",
    "        (torch.stack([re[0], im[0]]) * abs(stft_right)).permute(1, 2, 0).contiguous())\n",
    "    second_channel_complex_new_stft = torch.view_as_complex(\n",
    "        (torch.stack([re[1], im[1]]) * abs(stft_right)).permute(1, 2, 0).contiguous())\n",
    "\n",
    "    first_channel_output = torch.istft(first_channel_complex_new_stft, win_length=win_size, hop_length=hop,\n",
    "                                       window=hann_window, n_fft=win_size)\n",
    "    second_channel_output = torch.istft(second_channel_complex_new_stft, win_length=win_size, hop_length=hop,\n",
    "                                        window=hann_window, n_fft=win_size)\n",
    "    # append the two channels back together\n",
    "    return torch.stack([first_channel_output, second_channel_output])\n",
    "\n",
    "\n",
    "wav, sr = torchaudio.load('audio_16k/Basta_16k.wav')\n",
    "wav_08 = time_stretch(wav, 0.8)\n",
    "wav_12 = time_stretch(wav, 1.2)\n",
    "torchaudio.save(\"outputs/phase_vocoder_0_8.wav\", wav_08, sr)\n",
    "torchaudio.save('outputs/phase_vocoder_1_2.wav', wav_12, sr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The vocoder gives better results by better preserving the pitch. The reason for this is that vocoders are specifically designed to preserve the spectral envelope of the original signal, which is critical for preserving the perceived pitch. The spectral envelope captures the overall shape of the frequency spectrum, and it is often used to represent the pitch of a signal. When you stretch a signal using a basic stretch function, the spectral envelope may be altered, which can affect the perceived pitch of the signal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
